import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Generate synthetic data
np.random.seed(42)
n_samples = 1000
n_features = 5

X = np.random.rand(n_samples, n_features)
y = np.random.randint(0, 2, n_samples)  # Binary classification labels

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a baseline model without gender
baseline_model = RandomForestClassifier(random_state=42)
baseline_model.fit(X_train, y_train)
baseline_accuracy = accuracy_score(y_test, baseline_model.predict(X_test))

# Add gender to the features
X_gender = np.random.randint(0, 2, n_samples)  # Synthetic gender data (0: Female, 1: Male)
X_with_gender = np.column_stack((X, X_gender))

# Split data into train and test sets with gender
X_train_gender, X_test_gender, _, _ = train_test_split(X_with_gender, y, test_size=0.2, random_state=42)

# Train a model with gender
model_with_gender = RandomForestClassifier(random_state=42)
model_with_gender.fit(X_train_gender, y_train)
accuracy_with_gender = accuracy_score(y_test, model_with_gender.predict(X_test_gender))

# Print the results
print("Baseline Accuracy (without gender): {:.2f}%".format(baseline_accuracy * 100))
print("Accuracy with Gender: {:.2f}%".format(accuracy_with_gender * 100))

# Determine the threshold X where adding gender justifies the increase in accuracy
threshold_X = baseline_accuracy * 100
print("Threshold X: {:.2f}%".format(threshold_X))
